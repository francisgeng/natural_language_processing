{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Some of the functions below require an older version of torchtext than the default one Kaggle gives you.\n# IMPORTANT: Make sure that Internet is turned on!!! (Notebook options in the bar on the right)\n# IMPORTANT: If you're not already using Kaggle, we STRONGLY recommend you switch to Kaggle for hw1b in particular,\n# because copying our notebook will pin you to a Python version that lets you install the right version of torchtext.\n# On Colab you will have to downgrade your Python to e.g., 3.7 to do the below pip install, which is a pain to do.\n!pip install torchtext==0.10.0\nexit()","metadata":{"execution":{"iopub.status.busy":"2023-09-08T16:24:57.611667Z","iopub.execute_input":"2023-09-08T16:24:57.612095Z","iopub.status.idle":"2023-09-08T16:26:35.150194Z","shell.execute_reply.started":"2023-09-08T16:24:57.611997Z","shell.execute_reply":"2023-09-08T16:26:35.148576Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchtext==0.10.0\n  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext==0.10.0) (1.21.6)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.10.0) (4.64.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.10.0) (2.28.1)\nCollecting torch==1.9.0\n  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m913.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (2.1.0)\nInstalling collected packages: torch, torchtext\n  Attempting uninstall: torch\n    Found existing installation: torch 1.11.0\n    Uninstalling torch-1.11.0:\n      Successfully uninstalled torch-1.11.0\n  Attempting uninstall: torchtext\n    Found existing installation: torchtext 0.12.0\n    Uninstalling torchtext-0.12.0:\n      Successfully uninstalled torchtext-0.12.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 1.9.0 requires torch>=1.10.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.10.1 requires torch<1.13.0,>=1.10.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-1.9.0 torchtext-0.10.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# This block handles some basic setup and data loading.  \n# You shouldn't need to edit this, but if you want to \n# import other standard python packages, that is fine.\n\n# imports\nfrom collections import defaultdict, Counter\nimport numpy as np\nimport math\nimport tqdm\nimport random\nimport pdb\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchtext\n\nfrom torchtext.legacy import data\nfrom torchtext.legacy import datasets\n\n# download and load the data\ntext_field = data.Field()\ndatasets = datasets.WikiText2.splits(root='.', text_field=text_field)\n\ntrain_dataset, validation_dataset, test_dataset = datasets\n\ntext_field.build_vocab(train_dataset, validation_dataset, test_dataset)\nvocab = text_field.vocab\nvocab_size = len(vocab)\n\ntrain_text = train_dataset.examples[0].text # a list of tokens (strings)\nvalidation_text = validation_dataset.examples[0].text\n\nprint(validation_text[:30])","metadata":{"id":"X1ATX-_J7SjQ","executionInfo":{"status":"ok","timestamp":1614318181024,"user_tz":480,"elapsed":1116,"user":{"displayName":"Rudy Corona Rodriguez","photoUrl":"","userId":"02448394073714905143"}},"outputId":"22d9213d-2b3b-415a-960c-bbbe88533690","execution":{"iopub.status.busy":"2023-09-08T16:27:16.809300Z","iopub.execute_input":"2023-09-08T16:27:16.810866Z","iopub.status.idle":"2023-09-08T16:27:17.765833Z","shell.execute_reply.started":"2023-09-08T16:27:16.810815Z","shell.execute_reply":"2023-09-08T16:27:17.763446Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['<eos>', '=', 'Homarus', 'gammarus', '=', '<eos>', '<eos>', 'Homarus', 'gammarus', ',', 'known', 'as', 'the', 'European', 'lobster', 'or', 'common', 'lobster', ',', 'is', 'a', 'species', 'of', '<unk>', 'lobster', 'from', 'the', 'eastern', 'Atlantic', 'Ocean']\n","output_type":"stream"}]},{"cell_type":"code","source":"text_field.vocab.freqs['.']","metadata":{"id":"QoFMSckDFTop","execution":{"iopub.status.busy":"2023-09-07T05:46:08.977639Z","iopub.execute_input":"2023-09-07T05:46:08.978431Z","iopub.status.idle":"2023-09-07T05:46:08.987704Z","shell.execute_reply.started":"2023-09-07T05:46:08.978392Z","shell.execute_reply":"2023-09-07T05:46:08.986685Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"90077"},"metadata":{}}]},{"cell_type":"code","source":"from collections import defaultdict, Counter\nimport numpy as np\nimport math\nimport tqdm\nimport random\nimport pdb\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchtext","metadata":{"execution":{"iopub.status.busy":"2023-09-08T16:27:20.849361Z","iopub.execute_input":"2023-09-08T16:27:20.850154Z","iopub.status.idle":"2023-09-08T16:27:20.856419Z","shell.execute_reply.started":"2023-09-08T16:27:20.850106Z","shell.execute_reply":"2023-09-08T16:27:20.855259Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"We've implemented a unigram model here as a demonstration.","metadata":{"id":"g10PLGiZn0XY"}},{"cell_type":"code","source":"class UnigramModel:\n    def __init__(self, train_text):\n        self.counts = Counter(train_text)\n        self.total_count = len(train_text)\n\n    def probability(self, word):\n        return self.counts[word] / self.total_count\n\n    def next_word_probabilities(self, text_prefix):\n        \"\"\"Return a list of probabilities for each word in the vocabulary.\"\"\"\n        return [self.probability(word) for word in vocab.itos]\n\n    def perplexity(self, full_text):\n        \"\"\"Return the perplexity of the model on a text as a float.\n        \n        full_text -- a list of string tokens\n        \"\"\"\n        log_probabilities = []\n        for word in full_text:\n            # Note that the base of the log doesn't matter \n            # as long as the log and exp use the same base.\n            log_probabilities.append(math.log(self.probability(word), 2))\n        return 2 ** -np.mean(log_probabilities)\n\nunigram_demonstration_model = UnigramModel(train_text)\nprint('unigram validation perplexity:', \n      unigram_demonstration_model.perplexity(validation_text))\n\ndef check_validity(model):\n    \"\"\"Performs several sanity checks on your model:\n    1) That next_word_probabilities returns a valid distribution\n    2) That perplexity matches a perplexity calculated from next_word_probabilities\n\n    Although it is possible to calculate perplexity from next_word_probabilities, \n    it is still good to have a separate more efficient method that only computes \n    the probabilities of observed words.\n    \"\"\"\n\n    log_probabilities = []\n    for i in range(10):\n        prefix = validation_text[:i]\n        probs = model.next_word_probabilities(prefix)\n        assert min(probs) >= 0, \"Negative value in next_word_probabilities\"\n        assert max(probs) <= 1 + 1e-8, \"Value larger than 1 in next_word_probabilities\"\n        assert abs(sum(probs)-1) < 1e-4, \"next_word_probabilities do not sum to 1\"\n\n        word_id = vocab.stoi[validation_text[i]]\n        selected_prob = probs[word_id]\n        log_probabilities.append(math.log(selected_prob))\n\n    perplexity = math.exp(-np.mean(log_probabilities))\n    your_perplexity = model.perplexity(validation_text[:10])\n    assert abs(perplexity-your_perplexity) < 0.1, \"your perplexity does not \" + \\\n    \"match the one we calculated from `next_word_probabilities`,\\n\" + \\\n    \"at least one of `perplexity` or `next_word_probabilities` is incorrect.\\n\" + \\\n    f\"we calcuated {perplexity} from `next_word_probabilities`,\\n\" + \\\n    f\"but your perplexity function returned {your_perplexity} (on a small sample).\"\n\n\ncheck_validity(unigram_demonstration_model)","metadata":{"id":"B7ZHMVZzoPEH","executionInfo":{"status":"ok","timestamp":1614318184013,"user_tz":480,"elapsed":922,"user":{"displayName":"Rudy Corona Rodriguez","photoUrl":"","userId":"02448394073714905143"}},"outputId":"475b17e5-ab16-46a4-93ec-5b9a44b4874c","execution":{"iopub.status.busy":"2023-09-08T16:27:26.490169Z","iopub.execute_input":"2023-09-08T16:27:26.490616Z","iopub.status.idle":"2023-09-08T16:27:27.224832Z","shell.execute_reply.started":"2023-09-08T16:27:26.490581Z","shell.execute_reply":"2023-09-08T16:27:27.223776Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"unigram validation perplexity: 965.0860734119312\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To generate from a language model, we can sample one word at a time conditioning on the words we have generated so far.","metadata":{"id":"U4esz5XrEpNo"}},{"cell_type":"code","source":"def generate_text(model, n=20, prefix=('<eos>', '<eos>')):\n    prefix = list(prefix)\n    for _ in range(n):\n        probs = model.next_word_probabilities(prefix)\n        word = random.choices(vocab.itos, probs)[0]\n        prefix.append(word)\n    return ' '.join(prefix)\n\nprint(generate_text(unigram_demonstration_model))","metadata":{"id":"bfNj5nl4E7Zn","execution":{"iopub.status.busy":"2023-09-08T16:27:36.082923Z","iopub.execute_input":"2023-09-08T16:27:36.083415Z","iopub.status.idle":"2023-09-08T16:27:36.456366Z","shell.execute_reply.started":"2023-09-08T16:27:36.083377Z","shell.execute_reply":"2023-09-08T16:27:36.455376Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<eos> <eos> winning Its its younger . 1961 life feminine The should indie = of under of Files of superstructure Moon ,\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In fact there are many strategies to get better-sounding samples, such as only sampling from the top-k words or sharpening the distribution with a temperature.  You can read more about sampling from a language model in this recent paper: https://arxiv.org/pdf/1904.09751.pdf.","metadata":{"id":"wq-WtaM6F6kN"}},{"cell_type":"markdown","source":"You will need to submit some outputs from the models you implement for us to grade.  The following function will be used to generate the required output files.","metadata":{"id":"uuopg4rYjf2O"}},{"cell_type":"code","source":"!wget https://cal-cs288.github.io/sp21/project_files/proj_1/eval_prefixes.txt\n!wget https://cal-cs288.github.io/sp21/project_files/proj_1/eval_output_vocab.txt\n!wget https://cal-cs288.github.io/sp21/project_files/proj_1/eval_prefixes_short.txt\n!wget https://cal-cs288.github.io/sp21/project_files/proj_1/eval_output_vocab_short.txt\n\ndef save_truncated_distribution(model, filename, short=True):\n    \"\"\"Generate a file of truncated distributions.\n    \n    Probability distributions over the full vocabulary are large,\n    so we will truncate the distribution to a smaller vocabulary.\n\n    Please do not edit this function\n    \"\"\"\n    from tqdm import tqdm\n\n    vocab_name = 'eval_output_vocab'\n    prefixes_name = 'eval_prefixes'\n\n    if short: \n      vocab_name += '_short'\n      prefixes_name += '_short'\n\n    with open('{}.txt'.format(vocab_name), 'r') as eval_vocab_file:\n        eval_vocab = [w.strip() for w in eval_vocab_file]\n    eval_vocab_ids = [vocab.stoi[s] for s in eval_vocab]\n\n    all_selected_probabilities = []\n    with open('{}.txt'.format(prefixes_name), 'r') as eval_prefixes_file:\n        lines = eval_prefixes_file.readlines()\n        for line in tqdm(lines, leave=False):\n            prefix = line.strip().split(' ')\n            probs = model.next_word_probabilities(prefix)\n            selected_probs = np.array([probs[i] for i in eval_vocab_ids], dtype=np.float32)\n            all_selected_probabilities.append(selected_probs)\n\n    all_selected_probabilities = np.stack(all_selected_probabilities)\n    np.save(filename, all_selected_probabilities)\n    print('saved', filename)","metadata":{"id":"ZB6MKPbm4z9s","executionInfo":{"status":"ok","timestamp":1614318186687,"user_tz":480,"elapsed":830,"user":{"displayName":"Rudy Corona Rodriguez","photoUrl":"","userId":"02448394073714905143"}},"outputId":"3b7db928-270a-4150-f40b-ba7dadbc7d8e","execution":{"iopub.status.busy":"2023-09-08T16:27:54.484168Z","iopub.execute_input":"2023-09-08T16:27:54.484607Z","iopub.status.idle":"2023-09-08T16:27:58.927080Z","shell.execute_reply.started":"2023-09-08T16:27:54.484569Z","shell.execute_reply":"2023-09-08T16:27:58.925773Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"--2023-09-08 16:27:55--  https://cal-cs288.github.io/sp21/project_files/proj_1/eval_prefixes.txt\nResolving cal-cs288.github.io (cal-cs288.github.io)... 185.199.111.153, 185.199.110.153, 185.199.108.153, ...\nConnecting to cal-cs288.github.io (cal-cs288.github.io)|185.199.111.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 519055 (507K) [text/plain]\nSaving to: ‘eval_prefixes.txt.1’\n\neval_prefixes.txt.1 100%[===================>] 506.89K  --.-KB/s    in 0.05s   \n\n2023-09-08 16:27:55 (10.0 MB/s) - ‘eval_prefixes.txt.1’ saved [519055/519055]\n\n--2023-09-08 16:27:56--  https://cal-cs288.github.io/sp21/project_files/proj_1/eval_output_vocab.txt\nResolving cal-cs288.github.io (cal-cs288.github.io)... 185.199.111.153, 185.199.110.153, 185.199.108.153, ...\nConnecting to cal-cs288.github.io (cal-cs288.github.io)|185.199.111.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 12497 (12K) [text/plain]\nSaving to: ‘eval_output_vocab.txt.1’\n\neval_output_vocab.t 100%[===================>]  12.20K  --.-KB/s    in 0s      \n\n2023-09-08 16:27:56 (41.2 MB/s) - ‘eval_output_vocab.txt.1’ saved [12497/12497]\n\n--2023-09-08 16:27:57--  https://cal-cs288.github.io/sp21/project_files/proj_1/eval_prefixes_short.txt\nResolving cal-cs288.github.io (cal-cs288.github.io)... 185.199.111.153, 185.199.110.153, 185.199.108.153, ...\nConnecting to cal-cs288.github.io (cal-cs288.github.io)|185.199.111.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 105976 (103K) [text/plain]\nSaving to: ‘eval_prefixes_short.txt.1’\n\neval_prefixes_short 100%[===================>] 103.49K  --.-KB/s    in 0.03s   \n\n2023-09-08 16:27:57 (3.99 MB/s) - ‘eval_prefixes_short.txt.1’ saved [105976/105976]\n\n--2023-09-08 16:27:58--  https://cal-cs288.github.io/sp21/project_files/proj_1/eval_output_vocab_short.txt\nResolving cal-cs288.github.io (cal-cs288.github.io)... 185.199.111.153, 185.199.110.153, 185.199.108.153, ...\nConnecting to cal-cs288.github.io (cal-cs288.github.io)|185.199.111.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3802 (3.7K) [text/plain]\nSaving to: ‘eval_output_vocab_short.txt.1’\n\neval_output_vocab_s 100%[===================>]   3.71K  --.-KB/s    in 0s      \n\n2023-09-08 16:27:58 (46.9 MB/s) - ‘eval_output_vocab_short.txt.1’ saved [3802/3802]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"save_truncated_distribution(unigram_demonstration_model, \n                            'unigram_demonstration_predictions.npy')","metadata":{"id":"_nzVrTWcH67Q","execution":{"iopub.status.busy":"2023-09-07T05:46:30.417528Z","iopub.execute_input":"2023-09-07T05:46:30.418203Z","iopub.status.idle":"2023-09-07T05:46:45.722579Z","shell.execute_reply.started":"2023-09-07T05:46:30.418157Z","shell.execute_reply":"2023-09-07T05:46:45.721527Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"                                                  ","output_type":"stream"},{"name":"stdout","text":"saved unigram_demonstration_predictions.npy\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"markdown","source":"### N-gram Model\n\nNow it's time to implement an n-gram language model.\n\nBecause not every n-gram will have been observed in training, use add-alpha smoothing to make sure no output word has probability 0.\n\n$$P(w_2|w_1)=\\frac{C(w_1,w_2)+\\alpha}{C(w_1)+N\\alpha}$$\n\nwhere $N$ is the vocab size and $C$ is the count for the given bigram.  An alpha value around `3e-3`  should work.  Later, we'll replace this smoothing with model backoff.\n\nOne edge case you will need to handle is at the beginning of the text where you don't have `n-1` prior words.  You can handle this however you like as long as you produce a valid probability distribution, but just using a uniform distribution over the vocabulary is reasonable for the purposes of this project.\n\nA properly implemented bi-gram model should get a perplexity below 510 on the validation set.\n\n**Note**: Do not change the signature of the `next_word_probabilities` and `perplexity` functions.  We will use these as a common interface for all of the different model types.  Make sure these two functions call `n_gram_probability`, because later we are going to override `n_gram_probability` in a subclass. \nAlso, we suggest pre-computing and caching the counts $C$ when you initialize `NGramModel` for efficiency. ","metadata":{"id":"MEfUwbbS9vy0"}},{"cell_type":"code","source":"class NGramModel:\n    def __init__(self, train_text, n=2, alpha=3e-3):\n        # get counts and perform any other setup\n        self.n = n\n        self.smoothing = alpha\n        self.vocab = set(train_text)\n        self.vocab_size = len(self.vocab)\n        self.alpha = alpha\n\n        # YOUR CODE HERE\n        self.n_gram_counts = Counter([tuple(train_text[i:i+n]) for i in range(len(train_text)-n+1)])\n        self.n_1_gram_counts = Counter([tuple(train_text[i:i+n-1]) for i in range(len(train_text)-n+2)])\n\n\n    def n_gram_probability(self, n_gram):\n        \"\"\"Return the probability of the last word in an n-gram.\n        \n        n_gram -- a list of string tokens\n        returns the conditional probability of the last token given the rest.\n        \"\"\"\n        assert len(n_gram) == self.n\n\n        # YOUR CODE HERE\n        n_1_gram = tuple(n_gram[:-1])\n        numerator = self.n_gram_counts.get(tuple(n_gram), 0) + self.alpha\n        denominator = self.n_1_gram_counts.get(n_1_gram, 0) + self.vocab_size * self.alpha\n        return numerator / denominator\n\n\n\n    def next_word_probabilities(self, text_prefix):\n        \"\"\"Return a list of probabilities for each word in the vocabulary.\"\"\"\n\n        # YOUR CODE HERE\n        # use your function n_gram_probability\n        # vocab.itos contains a list of words to return probabilities for\n        probabilities = []\n        \n        if len(text_prefix) < self.n - 1:\n            return [1 / self.vocab_size for _ in self.vocab]\n        \n        text_prefix = text_prefix[-(self.n - 1):] if self.n > 1 else []\n        \n        for word in vocab.itos:\n            n_gram = text_prefix + [word]\n            prob = self.n_gram_probability(n_gram)\n            probabilities.append(prob)\n        \n        return probabilities\n        \n\n\n    def perplexity(self, full_text):\n        \"\"\" full_text is a list of string tokens\n        return perplexity as a float \"\"\"\n        N = len(full_text)\n        prob = []\n        \n        # Handle the first n-1 words as a special case (uniform distribution)\n        for i in range(min(self.n - 1, N)):\n            prob.append(math.log(1 / self.vocab_size))\n        \n        # Compute perplexity for the rest of the text\n        for i in range(self.n - 1, N):\n            n_gram = full_text[i-self.n+1:i+1]\n            prob.append(math.log(self.n_gram_probability(n_gram)))\n        \n        return math.exp(-np.mean(prob))\n        # YOUR CODE HERE\n        # use your function n_gram_probability\n        # This method should differ a bit from the example unigram model because \n        # the first n-1 words of full_text must be handled as a special case.\n\n\n\nunigram_model = NGramModel(train_text, 1)\ncheck_validity(unigram_model)\nprint('unigram validation perplexity:', unigram_model.perplexity(validation_text)) # this should be the almost the same as our unigram model perplexity above\n\nbigram_model = NGramModel(train_text, n=2)\ncheck_validity(bigram_model)\nprint('bigram validation perplexity:', bigram_model.perplexity(validation_text))\n\ntrigram_model = NGramModel(train_text, n=3)\ncheck_validity(trigram_model)\nprint('trigram validation perplexity:', trigram_model.perplexity(validation_text)) # this won't do very well...\n\nsave_truncated_distribution(bigram_model, 'bigram_predictions.npy') # this might take a few minutes","metadata":{"id":"YGnGpnPIXpTW","execution":{"iopub.status.busy":"2023-09-07T05:46:47.232205Z","iopub.execute_input":"2023-09-07T05:46:47.232588Z","iopub.status.idle":"2023-09-07T05:48:10.727516Z","shell.execute_reply.started":"2023-09-07T05:46:47.232552Z","shell.execute_reply":"2023-09-07T05:48:10.726399Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"unigram validation perplexity: 965.0918293231176\nbigram validation perplexity: 504.4263037850708\ntrigram validation perplexity: 2965.604234400349\n","output_type":"stream"},{"name":"stderr","text":"                                                  ","output_type":"stream"},{"name":"stdout","text":"saved bigram_predictions.npy\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"markdown","source":"Please download `bigram_predictions.npy` once you finish this section so that you can submit it.\n\nIn the block below, please report your bigram validation perplexity.  (We will use this to help us calibrate our scoring on the test set.)","metadata":{"id":"TzRRLnk73-r9"}},{"cell_type":"markdown","source":"<!-- Do not remove this comment, it is used by the autograder: RqYJKsoTS6 -->\n\nBigram validation perplexity: ***504.4263037850708***","metadata":{"id":"DEcUK27xVTcK"}},{"cell_type":"markdown","source":"We can also generate samples from the model to get an idea of how it is doing.","metadata":{"id":"qs6zgYw9VTx1"}},{"cell_type":"code","source":"print(generate_text(bigram_model))","metadata":{"id":"m2V-qHxB4yhS","execution":{"iopub.status.busy":"2023-09-07T05:48:10.729964Z","iopub.execute_input":"2023-09-07T05:48:10.730642Z","iopub.status.idle":"2023-09-07T05:48:12.199046Z","shell.execute_reply.started":"2023-09-07T05:48:10.730597Z","shell.execute_reply":"2023-09-07T05:48:12.197993Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"<eos> <eos> <eos> In Britain twenty @-@ watched by a fountain display AM convert boxer . The structures listed in the period\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We now free up some RAM, **it is important to run the cell below, otherwise you may quite possibly run out of RAM in the runtime.**","metadata":{"id":"VsR8_Ch7AXAZ"}},{"cell_type":"code","source":"# Free up some RAM. \ndel bigram_model\ndel trigram_model","metadata":{"id":"EjKt1ncf_ypz","execution":{"iopub.status.busy":"2023-09-07T05:48:43.497447Z","iopub.execute_input":"2023-09-07T05:48:43.497872Z","iopub.status.idle":"2023-09-07T05:48:43.682145Z","shell.execute_reply.started":"2023-09-07T05:48:43.497835Z","shell.execute_reply":"2023-09-07T05:48:43.680962Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"This basic model works okay for bigrams, but a better strategy (especially for higher-order models) is to use backoff.  Implement backoff with absolute discounting.\n$$P\\left(w_i|w_{i-n+1}^{i-1}\\right)=\\frac{max\\left\\{C(w_{i-n+1}^i)-\\delta,0\\right\\}}{\\sum_{w_i} C(w_{i-n+1}^i)} + \\alpha(w_{i-n+1}^{i-1}) P(w_i|w_{i-n+2}^{i-1})$$\n\n$$\\alpha\\left(w_{i-n+1}^{i-1}\\right)=\\frac{\\delta N_{1+}(w_{i-n+1}^{i-1})}{{\\sum_{w_i} C(w_{i-n+1}^i)}}$$\nwhere $N_{1+}$ is the number of words that appear after the previous $n-1$ words (the number of times the max will select something other than 0 in the first equation).  If $\\sum_{w_i} C(w_{i-n+1}^i)=0$, use the lower order model probability directly (the above equations would have a division by 0).\n\nWe found a discount $\\delta$ of 0.9 to work well based on validation performance.  A trigram model with this discount value should get a validation perplexity below 275.","metadata":{"id":"SWXNlsEKb3Mz"}},{"cell_type":"code","source":"class DiscountBackoffModel(NGramModel):\n    def __init__(self, train_text, lower_order_model, n=2, delta=0.9):\n        super().__init__(train_text, n=n)\n        self.lower_order_model = lower_order_model\n        self.discount = delta\n        self.N1plus = defaultdict(int)\n        for n_gram, c in self.n_gram_counts.items():\n            if c > 0:\n                self.N1plus[n_gram[:-1]] += 1\n\n        \n\n    def n_gram_probability(self, n_gram):\n        assert len(n_gram) == self.n\n        n_gram = tuple(n_gram)\n        n_1_gram = tuple(n_gram[:-1])\n\n        count_n_gram = self.n_gram_counts[n_gram]\n        count_n_1_gram = self.n_1_gram_counts[n_1_gram]\n#         count_n_1_gram = sum([c for ng, c in self.n_gram_counts.items() if ng[:-1] == n_1_gram])\n        \n        if count_n_1_gram == 0:\n            return self.lower_order_model.n_gram_probability(n_gram[1:])\n\n        max_term = max(count_n_gram - self.discount, 0) / count_n_1_gram\n        alpha = self.discount * self.N1plus[n_1_gram] / count_n_1_gram\n        lower_order_prob = self.lower_order_model.n_gram_probability(n_gram[1:])\n\n        return max_term + alpha * lower_order_prob\n\n\n\nbigram_backoff_model = DiscountBackoffModel(train_text, unigram_model, 2)\ntrigram_backoff_model = DiscountBackoffModel(train_text, bigram_backoff_model, 3)\ncheck_validity(trigram_backoff_model)\nprint('trigram backoff validation perplexity:', trigram_backoff_model.perplexity(validation_text))","metadata":{"id":"BV4e4_mEc7VY","execution":{"iopub.status.busy":"2023-09-07T05:48:45.670298Z","iopub.execute_input":"2023-09-07T05:48:45.670701Z","iopub.status.idle":"2023-09-07T05:48:58.277471Z","shell.execute_reply.started":"2023-09-07T05:48:45.670646Z","shell.execute_reply":"2023-09-07T05:48:58.276331Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"trigram backoff validation perplexity: 271.1218574337853\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Free up RAM. ","metadata":{"id":"LVrWYSMsBRSV"}},{"cell_type":"code","source":"# Release models we don't need any more. \ndel unigram_model\ndel bigram_backoff_model\ndel trigram_backoff_model","metadata":{"id":"_WJe_trXBTjN","execution":{"iopub.status.busy":"2023-09-07T05:49:04.980297Z","iopub.execute_input":"2023-09-07T05:49:04.981522Z","iopub.status.idle":"2023-09-07T05:49:05.250827Z","shell.execute_reply.started":"2023-09-07T05:49:04.981468Z","shell.execute_reply":"2023-09-07T05:49:05.249495Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Fill in your trigram backoff perplexity here.","metadata":{"id":"DPecL2jMXQ3y"}},{"cell_type":"markdown","source":"<!-- Do not remove this comment, it is used by the autograder: RqYJKsoTS6 -->\n\nTrigram backoff validation perplexity: ***271.1218574337853***\n\n","metadata":{"id":"AIBVAMe0WV_1"}},{"cell_type":"markdown","source":"Free up RAM. ","metadata":{"id":"s3TFBf1CBiwp"}},{"cell_type":"markdown","source":"### Neural N-gram Model\n\nIn this section, you will implement a neural version of an n-gram model.  The model will use a simple feedforward neural network that takes the previous `n-1` words and outputs a distribution over the next word.\n\nYou will use PyTorch to implement the model.  We've provided a little bit of code to help with the data loading using PyTorch's data loaders (https://pytorch.org/docs/stable/data.html)\n\nA model with the following architecture and hyperparameters should reach a validation perplexity below 226.\n* embed the words with dimension 128, then flatten into a single embedding for $n-1$ words (with size $(n-1)*128$)\n* run 2 hidden layers with 1024 hidden units, then project down to size 128 before the final layer (ie. 4 layers total). \n* use weight tying for the embedding and final linear layer (this made a very large difference in our experiments); you can do this by creating the output layer with `nn.Linear`, then using `F.embedding` with the linear layer's `.weight` to embed the input\n* rectified linear activation (ReLU) and dropout 0.1 after first 2 hidden layers. **Note: You will likely find a performance drop if you add a nonlinear activation function after the dimension reduction layer.**\n* train for 10 epochs with the Adam optimizer (should take around 15-20 minutes)\n* do early stopping based on validation set perplexity (see Project 0)\n\n\nWe encourage you to try other architectures and hyperparameters, and you will likely find some that work better than the ones listed above.  A proper implementation with these should be enough to receive full credit on the assignment, though.","metadata":{"id":"e5Y0S6XbB1iZ"}},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n\ndef ids(tokens):\n    return [vocab.stoi[t] for t in tokens]\n\nassert torch.cuda.is_available(), \"no GPU found, in Colab go to 'Edit->Notebook settings' and choose a GPU hardware accelerator\"\n\nclass NeuralNgramDataset(torch.utils.data.Dataset):\n    def __init__(self, text_token_ids, n):\n        self.text_token_ids = text_token_ids\n        self.n = n\n\n    def __len__(self):\n        return len(self.text_token_ids)\n\n    def __getitem__(self, i):\n        if i < self.n-1:\n            prev_token_ids = [vocab.stoi['<eos>']] * (self.n-i-1) + self.text_token_ids[:i]\n        else:\n            prev_token_ids = self.text_token_ids[i-self.n+1:i]\n\n        assert len(prev_token_ids) == self.n-1\n\n        x = torch.tensor(prev_token_ids)\n        y = torch.tensor(self.text_token_ids[i])\n        return x, y\n\n\nclass NeuralNGramNetwork(nn.Module):\n    def __init__(self, n, embed_dim=128, hidden_dim=1024, dropout=0.1):\n        super(NeuralNGramNetwork, self).__init__()\n        self.n = n\n        self.embed_dim = embed_dim\n\n        # Create the final layer first for weight tying\n        self.fc_final = nn.Linear(embed_dim, vocab_size)\n\n        # First two hidden layers with ReLU and dropout\n        self.fc1 = nn.Linear((n-1) * embed_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.dropout = nn.Dropout(0.1)\n\n        # Dimension reduction layer without ReLU\n        self.fc3 = nn.Linear(hidden_dim, embed_dim)\n\n\n    def forward(self, x):\n        x = x.long()  # Convert to Long type\n\n        # Use F.embedding and the weights of the final linear layer for embedding\n        x = F.embedding(x, self.fc_final.weight)\n\n        x = x.view(-1, (self.n - 1) * self.embed_dim)  # Flatten the tensor\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.fc_final(x)\n        \n        return F.log_softmax(x, dim=-1)\n    \n        \n        \n\n\n\nclass NeuralNGramModel:\n    def __init__(self, n):\n        self.n = n\n        self.network = NeuralNGramNetwork(n).cuda()\n        self.optimizer = optim.Adam(self.network.parameters())\n        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', patience=3)\n\n    def train(self):\n        min_val_perplexity = float('inf')\n        epochs_without_improvement = 0\n\n        self.network.train()\n        dataset = NeuralNgramDataset(ids(train_text), self.n)\n        train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n\n        for epoch in range(10):\n            pbar = tqdm(train_loader)\n            for x, y in pbar:\n                x, y = x.cuda(), y.cuda()\n                self.optimizer.zero_grad()\n                output = self.network(x)\n                loss = F.nll_loss(output, y)\n                loss.backward()\n                self.optimizer.step()\n                pbar.set_description(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n\n            val_perplexity = self.perplexity(validation_text)  # Assuming validation_text is defined\n            print(f\"Validation Perplexity after epoch {epoch+1}: {val_perplexity}\")\n\n            # Early stopping and learning rate scheduling\n            if val_perplexity < min_val_perplexity:\n                min_val_perplexity = val_perplexity\n                epochs_without_improvement = 0\n            else:\n                epochs_without_improvement += 1\n                if epochs_without_improvement >= 1:\n                    print(\"Early stopping due to no improvement in validation perplexity.\")\n                    break\n\n            self.scheduler.step(val_perplexity)\n\n    \n    def next_word_probabilities(self, text_prefix):\n        self.network.eval()\n        with torch.no_grad():\n            # Handle the case where text_prefix has fewer than n-1 tokens\n            if len(text_prefix) < self.n - 1:\n                text_prefix = ['<eos>'] * (self.n - 1 - len(text_prefix)) + text_prefix\n\n            x = torch.tensor(ids(text_prefix[-self.n+1:])).unsqueeze(0).cuda()\n\n            # Check that x is not empty\n            if x.nelement() == 0:\n                return []\n\n            output = self.network(x)\n            probs = torch.exp(output).squeeze().cpu().numpy()\n\n            # Check that probs is not empty\n            if len(probs) == 0:\n                return []\n\n            return probs\n\n\n    def perplexity(self, text):\n        self.network.eval()\n        dataset = NeuralNgramDataset(ids(text), self.n)\n        data_loader = DataLoader(dataset, batch_size=128)\n        total_loss = 0\n        total_count = 0\n        with torch.no_grad():\n            for x, y in data_loader:\n                x, y = x.cuda(), y.cuda()\n                output = self.network(x)\n                loss = F.nll_loss(output, y, reduction='sum').item()\n                total_loss += loss\n                total_count += y.size(0)\n        return torch.exp(torch.tensor(total_loss / total_count)).item()\n\nneural_trigram_model = NeuralNGramModel(3)\ncheck_validity(neural_trigram_model)\nneural_trigram_model.train()\nprint('neural trigram validation perplexity:', neural_trigram_model.perplexity(validation_text))\n\nsave_truncated_distribution(neural_trigram_model, 'neural_trigram_predictions.npy', short=False)","metadata":{"id":"jokaz820Fk1h","executionInfo":{"status":"error","timestamp":1614313717081,"user_tz":480,"elapsed":3609091,"user":{"displayName":"Rudy Corona Rodriguez","photoUrl":"","userId":"02448394073714905143"}},"outputId":"2f4cda3e-61f1-4c3b-b8e6-6fb55704b160","execution":{"iopub.status.busy":"2023-09-07T05:52:13.739276Z","iopub.execute_input":"2023-09-07T05:52:13.739932Z","iopub.status.idle":"2023-09-07T06:03:00.221617Z","shell.execute_reply.started":"2023-09-07T05:52:13.739883Z","shell.execute_reply":"2023-09-07T06:03:00.220397Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Epoch 1 Loss: 6.2276: 100%|██████████| 16318/16318 [02:36<00:00, 104.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after epoch 1: 235.6413116455078\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 Loss: 4.8589: 100%|██████████| 16318/16318 [02:35<00:00, 105.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after epoch 2: 211.1413116455078\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 Loss: 6.0954: 100%|██████████| 16318/16318 [02:33<00:00, 106.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after epoch 3: 209.91098022460938\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 Loss: 5.5778: 100%|██████████| 16318/16318 [02:35<00:00, 105.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after epoch 4: 213.18162536621094\nEarly stopping due to no improvement in validation perplexity.\nneural trigram validation perplexity: 213.18162536621094\n","output_type":"stream"},{"name":"stderr","text":"                                                     \r","output_type":"stream"},{"name":"stdout","text":"saved neural_trigram_predictions.npy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Fill in your neural trigram perplexity.","metadata":{"id":"sm-xW4FGXYYi"}},{"cell_type":"markdown","source":"<!-- Do not remove this comment, it is used by the autograder: RqYJKsoTS6 -->\n\nNeural trigram validation perplexity: ***213.18162536621094***","metadata":{"id":"Q0cX0k2IW88k"}},{"cell_type":"markdown","source":"Free up RAM.","metadata":{"id":"8t5PCZnkB1r5"}},{"cell_type":"code","source":"# Delete model we don't need. \ndel neural_trigram_model","metadata":{"id":"x1yH0lGOB1-S","execution":{"iopub.status.busy":"2023-09-07T06:05:00.455119Z","iopub.execute_input":"2023-09-07T06:05:00.455563Z","iopub.status.idle":"2023-09-07T06:05:00.463195Z","shell.execute_reply.started":"2023-09-07T06:05:00.455526Z","shell.execute_reply":"2023-09-07T06:05:00.460850Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### LSTM Model\n\nFor this stage of the project, you will implement an LSTM language model.\n\nFor recurrent language modeling, the data batching strategy is a bit different from what is used in some other tasks.  Sentences are concatenated together so that one sentence starts right after the other, and an unfinished sentence will be continued in the next batch.  We'll use the `torchtext` library to manage this batching for you.  To properly deal with this input format, you should save the last state of the LSTM from a batch to feed in as the first state of the next batch.  When you save state across different batches, you should call `.detach()` on the state tensors before the next batch to tell PyTorch not to backpropagate gradients through the state into the batch you have already finished (which will cause a runtime error).\n\nWe expect your model to reach a validation perplexity below 130.  The following architecture and hyperparameters should be sufficient to get there.\n* 3 LSTM layers with 512 units\n* dropout of 0.5 after each LSTM layer\n* instead of projecting directly from the last LSTM output to the vocabulary size for softmax, project down to a smaller size first (e.g. 512->128->vocab_size). **NOTE: You may find that adding nonlinearities between these layers can hurt performance, try without first.**\n* use the same weights for the embedding layer and the pre-softmax layer; dimension 128\n* train with Adam (using default learning rates) for at least 20 epochs\n","metadata":{"id":"qOp1Gb_0WjlE"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchtext.legacy import data\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\n# Assuming vocab and train_dataset are defined and loaded somewhere\n# vocab.stoi is a dictionary that converts string to index\n# train_dataset is a dataset object\n\ndef ids(tokens):\n    return [vocab.stoi[t] for t in tokens]\n\n\nclass LSTMNetwork(nn.Module):\n    def __init__(self, vocab_size, embed_size=128, hidden_size=512, num_layers=3, dropout=0.4):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, dropout=dropout)\n        self.fc1 = nn.Linear(hidden_size, embed_size)\n        self.fc2 = nn.Linear(embed_size, vocab_size)\n        self.fc2.weight = self.embedding.weight  # Tie weights\n\n    def forward(self, x, state):\n        x = self.embedding(x)\n        x, new_state = self.lstm(x, state)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x, new_state\n\nclass LSTMModel:\n    def __init__(self):\n        vocab_size = len(train_dataset.fields['text'].vocab)\n        self.network = LSTMNetwork(vocab_size).cuda()\n        self.optimizer = optim.Adam(self.network.parameters())\n        self.criterion = nn.CrossEntropyLoss()\n        \n\n    def train(self):\n        epochs = 25\n        epochs_without_improvement = 0\n        min_val_perplexity = float('inf')\n        epoch_loss = 0\n        for epoch in range(epochs):\n            self.network.train()\n            state_h, state_c = torch.zeros(3, 64, 512).cuda(), torch.zeros(3, 64, 512).cuda()\n            train_iterator = data.BPTTIterator(train_dataset, batch_size=64, bptt_len=32, device='cuda')\n            pbar = tqdm(train_iterator, position=0, leave=True)  # Initialize tqdm\n            \n            for batch in pbar:\n                self.optimizer.zero_grad()\n                output, (state_h, state_c) = self.network(batch.text, (state_h.detach(), state_c.detach()))\n                loss = self.criterion(output.view(-1, output.size(2)), batch.target.view(-1))\n                loss.backward()\n                self.optimizer.step()\n                epoch_loss += loss.item()\n                \n                pbar.set_description(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n            val_perplexity = self.dataset_perplexity(validation_dataset)\n            print(f\"Validation Perplexity after Epoch {epoch+1}: {val_perplexity}\")\n            if val_perplexity < min_val_perplexity:\n                min_val_perplexity = val_perplexity\n                epochs_without_improvement = 0\n            else:\n                epochs_without_improvement += 1\n                if epochs_without_improvement >= 2:\n                    print(\"Early stopping due to no improvement in validation perplexity.\")\n                    break\n                    \n    def next_word_probabilities(self, text_prefix):\n        self.network.eval()\n        with torch.no_grad():\n            prefix_token_tensor = torch.tensor(ids(text_prefix), device='cuda').view(-1, 1)\n            output, _ = self.network(prefix_token_tensor, None)\n            probs = torch.exp(output[-1]).squeeze().cpu().numpy()\n        return probs\n\n    def dataset_perplexity(self, torchtext_dataset):\n        self.network.eval()\n        vocab_size = len(torchtext_dataset.fields['text'].vocab)\n        total_loss = 0\n        total_count = 0\n        iterator = data.BPTTIterator(torchtext_dataset, batch_size=64, bptt_len=32, device='cuda')\n        with torch.no_grad():\n            state_h, state_c = torch.zeros(3, 64, 512).cuda(), torch.zeros(3, 64, 512).cuda()\n            for batch in iterator:\n                output, (state_h, state_c) = self.network(batch.text, (state_h.detach(), state_c.detach()))\n                loss = self.criterion(output.view(-1, vocab_size), batch.target.view(-1))\n                total_loss += loss.item() * np.prod(batch.target.shape)\n                total_count += np.prod(batch.target.shape)\n        perplexity = np.exp(total_loss / total_count)\n        return perplexity\n    \n\n# Assuming train_dataset and validation_dataset are already prepared\nlstm_model = LSTMModel()\nlstm_model.train()\n\nprint('Final LSTM validation perplexity:', lstm_model.dataset_perplexity(validation_dataset))\n","metadata":{"id":"0qOLXKKoc7If","outputId":"0516ca99-c13d-4968-a677-be29f7c2b839","execution":{"iopub.status.busy":"2023-09-08T17:28:39.277092Z","iopub.execute_input":"2023-09-08T17:28:39.277519Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1 Loss: 6.3552:  77%|███████▋  | 785/1020 [00:48<00:14, 16.37it/s]","output_type":"stream"}]},{"cell_type":"code","source":"save_truncated_distribution(lstm_model, 'lstm_predictions.npy', short=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-07T05:27:21.685391Z","iopub.execute_input":"2023-09-07T05:27:21.685861Z","iopub.status.idle":"2023-09-07T05:27:33.642048Z","shell.execute_reply.started":"2023-09-07T05:27:21.685827Z","shell.execute_reply":"2023-09-07T05:27:33.640967Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"                                                    ","output_type":"stream"},{"name":"stdout","text":"saved lstm_predictions.npy\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"del lstm_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- Do not remove this comment, it is used by the autograder: RqYJKsoTS6 -->\n\nFill in your LSTM perplexity. \n\nLSTM validation perplexity: ***129.35680852165908***","metadata":{"id":"7pGhdPQqHx9v"}},{"cell_type":"markdown","source":"# Experimentation: 1-Page Report\n\nNow it's time for you to experiment.  Try to reach a validation perplexity below 120. You may either modify the LSTM class above, or copy it down to the code cell below and modify it there. Just **be sure to run code cell below to generate results with your improved LSTM**.  \n\nIt is okay if the bulk of your improvements are due to hyperparameter tuning (such as changing number or sizes of layers), but implement at least one more substantial change to the model.  Here are some ideas (several of which come from https://arxiv.org/pdf/1708.02182.pdf):\n* activation regularization - add a l2 regularization penalty on the activation of the LSTM output (standard l2 regularization is on the weights)\n* weight-drop regularization - apply dropout to the weight matrices instead of activations\n* learning rate scheduling - decrease the learning rate during training\n* embedding dropout - zero out the entire embedding for a random set of words in the embedding matrix\n* ensembling - average the predictions of several models trained with different initialization random seeds\n* temporal activation regularization - add l2 regularization on the difference between the LSTM output activations at adjacent timesteps\n\nYou may notice that most of these suggestions are regularization techniques.  This dataset is considered fairly small, so regularization is one of the best ways to improve performance.\n\nFor this section, you will submit a write-up describing the extensions and/or modifications that you tried.  Your write-up should be **1-page maximum** in length and should be submitted in PDF format.  You may use any editor you like, but we recommend using LaTeX and working in an environment like Overleaf.\nFor full credit, your write-up should include:\n1.   A concise and precise description of the extension that you tried.\n2.   A motivation for why you believed this approach might improve your model.\n3.   A discussion of whether the extension was effective and/or an analysis of the results.  This will generally involve some combination of tables, learning curves, etc.\n4.   A bottom-line summary of your results comparing validation perplexities of your improvement to the original LSTM.\nThe purpose of this exercise is to experiment, so feel free to try/ablate multiple of the suggestions above as well as any others you come up with!\nWhen you submit the file, please name it `report.pdf`.\n\n","metadata":{"id":"kLoiXBWMaSPc"}},{"cell_type":"markdown","source":"Run the cell below in order to train your improved LSTM and evaluate it.  ","metadata":{"id":"i4fxj-BQTDgU"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchtext.legacy import data\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport numpy as np\n\n# Assuming vocab and train_dataset are defined and loaded somewhere\n# vocab.stoi is a dictionary that converts string to index\n# train_dataset is a dataset object\n\ndef ids(tokens):\n    return [vocab.stoi[t] for t in tokens]\n\nclass LSTMNetwork(nn.Module):\n    def __init__(self, vocab_size, embed_size=128, hidden_size=512, num_layers=3, dropout=0.4):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, dropout=dropout)\n        self.fc1 = nn.Linear(hidden_size, embed_size)\n        self.fc2 = nn.Linear(embed_size, vocab_size)\n        self.fc2.weight = self.embedding.weight  # Tie weights\n\n    def forward(self, x, state):\n        x = self.embedding(x)\n        x, new_state = self.lstm(x, state)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x, new_state\n\nclass LSTMModel:\n    def __init__(self):\n        vocab_size = len(train_dataset.fields['text'].vocab)\n        self.network = LSTMNetwork(vocab_size).cuda()\n        self.optimizer = optim.AdamW(self.network.parameters(), lr=0.004, weight_decay=0.02)\n        self.criterion = nn.CrossEntropyLoss()\n        self.activation_reg = 0.001  # Hyperparameter for activation regularization\n\n    def train(self):\n        epochs = 25\n        epochs_without_improvement = 0\n        min_val_perplexity = float('inf')\n        \n        for epoch in range(epochs):\n            self.network.train()\n            state_h, state_c = torch.zeros(3, 64, 512).cuda(), torch.zeros(3, 64, 512).cuda()\n            train_iterator = data.BPTTIterator(train_dataset, batch_size=64, bptt_len=32, device='cuda')\n            pbar = tqdm(train_iterator, position=0, leave=True)\n            \n            for batch in pbar:\n                self.optimizer.zero_grad()\n                output, (state_h, state_c) = self.network(batch.text, (state_h.detach(), state_c.detach()))\n                \n                # Activation Regularization\n                ar_loss = self.activation_reg * torch.norm(state_h, 2)\n                \n                loss = self.criterion(output.view(-1, output.size(2)), batch.target.view(-1)) + ar_loss\n                loss.backward()\n                self.optimizer.step()\n                \n                pbar.set_description(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n            \n            val_perplexity = self.dataset_perplexity(validation_dataset)\n            print(f\"Validation Perplexity after Epoch {epoch+1}: {val_perplexity}\")\n            if val_perplexity < 120:\n                print(\"Achieved goal in validation perplexity.\")\n                break\n\n    def next_word_probabilities(self, text_prefix):\n        self.network.eval()\n        with torch.no_grad():\n            prefix_token_tensor = torch.tensor(ids(text_prefix), device='cuda').view(-1, 1)\n            output, _ = self.network(prefix_token_tensor, None)\n            probs = torch.exp(output[-1]).squeeze().cpu().numpy()\n        return probs\n\n    def dataset_perplexity(self, torchtext_dataset):\n        self.network.eval()\n        vocab_size = len(torchtext_dataset.fields['text'].vocab)\n        total_loss = 0\n        total_count = 0\n        iterator = data.BPTTIterator(torchtext_dataset, batch_size=64, bptt_len=32, device='cuda')\n        with torch.no_grad():\n            state_h, state_c = torch.zeros(3, 64, 512).cuda(), torch.zeros(3, 64, 512).cuda()\n            for batch in iterator:\n                output, (state_h, state_c) = self.network(batch.text, (state_h.detach(), state_c.detach()))\n                loss = self.criterion(output.view(-1, vocab_size), batch.target.view(-1))\n                total_loss += loss.item() * np.prod(batch.target.shape)\n                total_count += np.prod(batch.target.shape)\n        perplexity = np.exp(total_loss / total_count)\n        return perplexity\n\n# Assuming train_dataset and validation_dataset are already prepared\nlstm_model = LSTMModel()\nlstm_model.train()\n\nprint('Final LSTM validation perplexity:', lstm_model.dataset_perplexity(validation_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T10:02:53.849355Z","iopub.execute_input":"2023-09-09T10:02:53.849832Z","iopub.status.idle":"2023-09-09T10:13:48.857004Z","shell.execute_reply.started":"2023-09-09T10:02:53.849793Z","shell.execute_reply":"2023-09-09T10:13:48.855282Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Epoch 1 Loss: 5.8793: 100%|██████████| 1020/1020 [01:02<00:00, 16.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 1: 269.3469392054884\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 Loss: 5.3630: 100%|██████████| 1020/1020 [01:02<00:00, 16.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 2: 188.69458503512863\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 Loss: 5.1448: 100%|██████████| 1020/1020 [01:02<00:00, 16.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 3: 157.4866147808746\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 Loss: 4.9047: 100%|██████████| 1020/1020 [01:02<00:00, 16.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 4: 141.2383748990779\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 Loss: 4.7379: 100%|██████████| 1020/1020 [01:02<00:00, 16.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 5: 131.24507584044656\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 Loss: 4.5795: 100%|██████████| 1020/1020 [01:02<00:00, 16.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 6: 126.6753681068441\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 Loss: 4.4282: 100%|██████████| 1020/1020 [01:02<00:00, 16.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 7: 122.26222881371113\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 Loss: 4.2923: 100%|██████████| 1020/1020 [01:02<00:00, 16.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 8: 120.41741088204954\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 Loss: 4.2031: 100%|██████████| 1020/1020 [01:02<00:00, 16.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 9: 120.08858215676867\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 Loss: 4.1197: 100%|██████████| 1020/1020 [01:03<00:00, 16.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Perplexity after Epoch 10: 119.92733688884104\nAchieved goal in validation perplexity.\nFinal LSTM validation perplexity: 119.92733688884104\n","output_type":"stream"}]},{"cell_type":"code","source":"save_truncated_distribution(lstm_model, 'lstm_predictions.npy', short=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T10:27:48.005412Z","iopub.execute_input":"2023-09-09T10:27:48.006597Z","iopub.status.idle":"2023-09-09T10:28:00.509005Z","shell.execute_reply.started":"2023-09-09T10:27:48.006536Z","shell.execute_reply":"2023-09-09T10:28:00.507745Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"                                                    \r","output_type":"stream"},{"name":"stdout","text":"saved lstm_predictions.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Losses for the first set of epochs\nlosses1 = [5.8793, 5.3630, 5.1448, 4.9047, 4.7379, 4.5795, 4.4282, 4.2923, 4.2031, 4.1197]\n\n# Losses for the second set of epochs\nlosses2 = [6.3274, 5.9538, 5.6666, 5.4555, 5.2472, 5.0994, 4.9875, 4.8960, 4.7975, 4.7402, 4.6643, 4.6440, 4.5652, 4.5342, 4.4873, 4.4583, 4.4114, 4.3477, 4.2910, 4.2920, 4.2456, 4.2280, 4.1792, 4.1471, 4.1516]\n\n# Epochs\nepochs1 = list(range(1, len(losses1) + 1))\nepochs2 = list(range(1, len(losses2) + 1))\n\n# Create the plot\nplt.figure(figsize=(12, 6))\n\n# Plot the first set of losses\nplt.plot(epochs1, losses1, marker='o', linestyle='-', label='LSTM with AR')\n\n# Plot the second set of losses\nplt.plot(epochs2, losses2, marker='x', linestyle='--', label='Original LSTM')\n\n# Add title and labels\nplt.title('Loss Curves Comparison')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\n# Add legend\nplt.legend()\n\n# Show grid\nplt.grid(True)\n\n# Show the plot\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T10:30:51.957918Z","iopub.execute_input":"2023-09-09T10:30:51.958381Z","iopub.status.idle":"2023-09-09T10:30:52.220250Z","shell.execute_reply.started":"2023-09-09T10:30:51.958340Z","shell.execute_reply":"2023-09-09T10:30:52.219268Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Submission\n\nUpload a submission with the following files to Gradescope:\n* hw1b.ipynb (rename to match this exactly)\n* lstm_predictions.npy (this should also include all improvements from your exploration)\n* neural_trigram_predictions.npy\n* bigram_predictions.npy\n* report.pdf\n\nYou can upload files individually or as part of a zip file, but if using a zip file be sure you are zipping the files directly and not a folder that contains them.\n\nBe sure to check the output of the autograder after it runs.  It should confirm that no files are missing and that the output files have the correct format.  Note that the test set perplexities shown by the autograder are on a completely different scale from your validation set perplexities due to truncating the distribution and selecting different text.  Don't worry if the values seem much worse.","metadata":{"id":"BHTOfrCG8CRF"}}]}